{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np \n",
    "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda\n",
    "from keras import backend as K\n",
    "from keras.activations import sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 临床数据fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 143 images belonging to 5 classes.\n",
      "样本总数为：\n",
      "143\n"
     ]
    }
   ],
   "source": [
    "test_dir = r'E:\\1_code\\图像分类\\数据分析\\武大\\外部数据集测试\\医院数据\\train\\dataset\\testdataset'\n",
    "\n",
    "height = 256#猴子图片的高度\n",
    "width = 256#猴子图片的长度\n",
    "channels = 3#彩色图片\n",
    "batch_size = 10#每一次64个图片\n",
    "num_classes = 5#最后是5分类\n",
    "SEED=666\n",
    "\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator()#验证集不用添加图片，只需要将图片像素值进行规定\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                    target_size = (height, width),\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    seed = SEED,\n",
    "                                                    shuffle = False,\n",
    "                                                    class_mode = \"categorical\")\n",
    "test_num = test_generator.samples#获取训练样本总数\n",
    "print(\"样本总数为：\")\n",
    "print(test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_1 (Functional)           [(None, 64, 64, 128  87566470    ['input_1[0][0]']                \n",
      "                                ),                                                                \n",
      "                                 (None, 32, 32, 256                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 16, 16, 512                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 8, 8, 1024)                                               \n",
      "                                , (None, 1024)]                                                   \n",
      "                                                                                                  \n",
      " model_3 (Functional)           [(None, 64, 64, 192  195198522   ['input_1[0][0]']                \n",
      "                                ),                                                                \n",
      "                                 (None, 32, 32, 384                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 16, 16, 768                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 8, 8, 1536)                                               \n",
      "                                , (None, 1536)]                                                   \n",
      "                                                                                                  \n",
      " build_model_main_Concatenate (  (None, 2560)        0           ['model_1[0][4]',                \n",
      " Concatenate)                                                     'model_3[0][4]']                \n",
      "                                                                                                  \n",
      " build_model_main_Dropout_1 (Dr  (None, 2560)        0           ['build_model_main_Concatenate[0]\n",
      " opout)                                                          [0]']                            \n",
      "                                                                                                  \n",
      " build_model_main_Dense_1 (Dens  (None, 512)         1311232     ['build_model_main_Dropout_1[0][0\n",
      " e)                                                              ]']                              \n",
      "                                                                                                  \n",
      " build_model_main_LeakyReLU (Le  (None, 512)         0           ['build_model_main_Dense_1[0][0]'\n",
      " akyReLU)                                                        ]                                \n",
      "                                                                                                  \n",
      " build_model_Concatenate_0 (Con  (None, 64, 64, 320)  0          ['model_1[0][0]',                \n",
      " catenate)                                                        'model_3[0][0]']                \n",
      "                                                                                                  \n",
      " build_model_Concatenate_1 (Con  (None, 32, 32, 640)  0          ['model_1[0][1]',                \n",
      " catenate)                                                        'model_3[0][1]']                \n",
      "                                                                                                  \n",
      " build_model_Concatenate_2 (Con  (None, 16, 16, 1280  0          ['model_1[0][2]',                \n",
      " catenate)                      )                                 'model_3[0][2]']                \n",
      "                                                                                                  \n",
      " build_model_Concatenate_3 (Con  (None, 8, 8, 2560)  0           ['model_1[0][3]',                \n",
      " catenate)                                                        'model_3[0][3]']                \n",
      "                                                                                                  \n",
      " build_model_main_Dropout_2 (Dr  (None, 512)         0           ['build_model_main_LeakyReLU[0][0\n",
      " opout)                                                          ]']                              \n",
      "                                                                                                  \n",
      " build_model_main_sq0 (Sequenti  (None, 5)           184965      ['build_model_Concatenate_0[0][0]\n",
      " al)                                                             ']                               \n",
      "                                                                                                  \n",
      " build_model_main_sq1 (Sequenti  (None, 5)           369285      ['build_model_Concatenate_1[0][0]\n",
      " al)                                                             ']                               \n",
      "                                                                                                  \n",
      " build_model_main_sq2 (Sequenti  (None, 5)           737925      ['build_model_Concatenate_2[0][0]\n",
      " al)                                                             ']                               \n",
      "                                                                                                  \n",
      " build_model_main_sq (Sequentia  (None, 5)           1475205     ['build_model_Concatenate_3[0][0]\n",
      " l)                                                              ']                               \n",
      "                                                                                                  \n",
      " build_model_main_Dense_2 (Dens  (None, 5)           2565        ['build_model_main_Dropout_2[0][0\n",
      " e)                                                              ]']                              \n",
      "                                                                                                  \n",
      " build_model_main_softmax_0 (Ac  (None, 5)           0           ['build_model_main_sq0[0][0]']   \n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " build_model_main_softmax_1 (Ac  (None, 5)           0           ['build_model_main_sq1[0][0]']   \n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " build_model_main_softmax_2 (Ac  (None, 5)           0           ['build_model_main_sq2[0][0]']   \n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " build_model_main_softmax_3 (Ac  (None, 5)           0           ['build_model_main_sq[0][0]']    \n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " build_model_All_num_classes (A  (None, 5)           0           ['build_model_main_Dense_2[0][0]'\n",
      " ctivation)                                                      ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 286,846,169\n",
      "Trainable params: 286,845,657\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, print_function\n",
    "\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.callbacks import (LearningRateScheduler, ModelCheckpoint,\n",
    "                                        ReduceLROnPlateau)\n",
    "from tensorflow.keras.layers import (Activation, Add, AveragePooling2D,\n",
    "                                     BatchNormalization, Concatenate, Conv1D,\n",
    "                                     Conv2D, Dense, Dropout, Flatten,\n",
    "                                     GlobalAveragePooling2D,\n",
    "                                     GlobalMaxPooling2D, Input, Lambda,\n",
    "                                     LeakyReLU, Multiply, Permute, Reshape,\n",
    "                                     multiply,ReLU)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adagrad, Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras import layers\n",
    "from keras import initializers\n",
    "import math\n",
    "from model1 import ConvNeXtBase, LayerScale\n",
    "from model2 import SwinTransformerLarge384\n",
    "class LayerScale(layers.Layer):\n",
    "    \"\"\"Layer scale module.\n",
    "\n",
    "    References:\n",
    "    - https://arxiv.org/abs/2103.17239\n",
    "\n",
    "    Args:\n",
    "    init_values (float): Initial value for layer scale. Should be within\n",
    "        [0, 1].\n",
    "    projection_dim (int): Projection dimensionality.\n",
    "\n",
    "    Returns:\n",
    "    Tensor multiplied to the scale.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, init_values, projection_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.init_values = init_values\n",
    "        self.projection_dim = projection_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = self.add_weight(\n",
    "            name=\"gamma\",\n",
    "            shape=(self.projection_dim,),\n",
    "            initializer=initializers.Constant(self.init_values),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        return x * self.gamma\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"init_values\": self.init_values,\n",
    "                \"projection_dim\": self.projection_dim,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "    \n",
    "def LightAttentionBlock(inputs,b=1, gamma=2,name=''):\n",
    "    # 通道注意力机制\n",
    "    channels = inputs.shape[-1]\n",
    "    t = int(abs((math.log(channels, 2) + b) / gamma))\n",
    "    k = t if t % 2 else t + 1\n",
    "    x_global_avg_pool = GlobalAveragePooling2D(name=name+'GlobalAveragePooling2D')(inputs)\n",
    "    x = Reshape((channels,1),name=name+'Reshape')(x_global_avg_pool)\n",
    "    x = Conv1D(1, kernel_size=k,padding=\"same\",name=name+'Conv1D')(x)\n",
    "    x = Activation('sigmoid',name=name+'Activation')(x)\n",
    "    x = Reshape((1, 1, channels),name=name+'Reshape2')(x)\n",
    "    output = Multiply(name=name+'Multiply')([inputs,x])\n",
    "\n",
    "    # 空间注意力机制\n",
    "    x = tf.reduce_mean(output,axis=-1,keepdims=True,name=name+'reduce_mean')\n",
    "    x = Activation('sigmoid',name=name+'Activation2')(x)\n",
    "    output = Multiply(name=name+'Multiply2')([x, output])\n",
    "    return output\n",
    "\n",
    "\n",
    "def ConvNeXtBase_build_model(inputs_dim,num_classes,\n",
    "                            input_shape=(512, 512, 3)):\n",
    "    x_0,x_1,x_2,x_3,x = ConvNeXtBase(include_top=False,\n",
    "                    weights='imagenet',\n",
    "                    input_shape=input_shape)(inputs_dim)\n",
    "\n",
    "    x = LightAttentionBlock(x,name='build_model_')\n",
    "    x = GlobalAveragePooling2D(\n",
    "        name='build_model_ConvNeXtBase_main_GlobalAveragePooling2D')(x)\n",
    "    dp_1 = Dropout(0.5, name='build_model_ConvNeXtBase_main_Dropout1')(x)\n",
    "    fc2_num_classes = Dense(\n",
    "        512,\n",
    "        kernel_initializer='he_normal',\n",
    "        name='build_model_ConvNeXtBase_main_Dense_3')(dp_1)\n",
    "    dp_2 = Dropout(0.5, name='build_model_ConvNeXtBase_main_Dropout2')(fc2_num_classes)\n",
    "    fc2_num_classes2 = Dense(\n",
    "        num_classes,\n",
    "        kernel_initializer='he_normal',\n",
    "        name='build_model_ConvNeXtBase_main_Dense_4')(dp_2)\n",
    "    fc2_num_classes2 = Activation(\n",
    "        'softmax', name='build_model_ConvNeXtBase')(fc2_num_classes2)\n",
    "    model = Model(inputs=inputs_dim, outputs=[x_0,x_1,x_2,x_3,fc2_num_classes2])\n",
    "    # model.load_weights('/home/luyaping_w/project/code/EyeDR/DeepEnsembleLearning/SwinTransformerConvNeXt/0_数据预处理对比/Fusion/Test/model_1_weights.h5')\n",
    "    \n",
    "    model = Model(inputs=model.input, \n",
    "                outputs=[model.output[0],model.output[1],model.output[2],model.output[3],model.get_layer('build_model_ConvNeXtBase_main_GlobalAveragePooling2D').output])\n",
    "    return model\n",
    "\n",
    "def SwinTransformerLarge384_build_model(inputs_dim,num_classes,\n",
    "                            input_shape=(512, 512, 3)):\n",
    "    x_0,x_1,x_2,x_3,x = SwinTransformerLarge384(include_top=False,\n",
    "                    weights='imagenet',\n",
    "                    input_shape=input_shape)(inputs_dim)\n",
    "\n",
    "    x = LightAttentionBlock(x,name='build_model_')\n",
    "    x = GlobalAveragePooling2D(\n",
    "        name='build_model_SwinTransformerLarge384_main_GlobalAveragePooling2D')(x)\n",
    "    dp_1 = Dropout(0.5, name='build_model_SwinTransformerLarge384_main_Dropout1')(x)\n",
    "    fc2_num_classes = Dense(\n",
    "        512,\n",
    "        kernel_initializer='he_normal',\n",
    "        name='build_model_SwinTransformerLarge384_main_Dense_3')(dp_1)\n",
    "    dp_2 = Dropout(0.5, name='build_model_SwinTransformerLarge384_main_Dropout2')(fc2_num_classes)\n",
    "    fc2_num_classes2 = Dense(\n",
    "        num_classes,\n",
    "        kernel_initializer='he_normal',\n",
    "        name='build_model_SwinTransformerLarge384_main_Dense_4')(dp_2)\n",
    "    fc2_num_classes2 = Activation(\n",
    "        'softmax', name='build_model_SwinTransformerLarge384')(fc2_num_classes2)\n",
    "    model = Model(inputs=inputs_dim, outputs=[x_0,x_1,x_2,x_3,fc2_num_classes2])\n",
    "    # model.load_weights('/home/luyaping_w/project/code/EyeDR/DeepEnsembleLearning/SwinTransformerConvNeXt/0_数据预处理对比/Fusion/Test/model_2_weights.h5',by_name=True, skip_mismatch=True)\n",
    "    \n",
    "    model = Model(inputs=model.input, \n",
    "                outputs=[model.output[0],model.output[1],model.output[2],model.output[3],model.get_layer('build_model_SwinTransformerLarge384_main_GlobalAveragePooling2D').output])\n",
    "    return model\n",
    "\n",
    "def build_model(num_classes, input_shape):\n",
    "    inputs_dim = Input(input_shape)\n",
    "    ConvNeXtBase_0,ConvNeXtBase_1,ConvNeXtBase_2,ConvNeXtBase_3,ConvNeXtBase_num_classes = ConvNeXtBase_build_model(\n",
    "        inputs_dim, num_classes, (input_shape[0], input_shape[1], input_shape[2]))(inputs_dim)\n",
    "    SwinTransformerLarge384_0,SwinTransformerLarge384_1,SwinTransformerLarge384_2,SwinTransformerLarge384_3, SwinTransformerLarge384_0_num_classes = SwinTransformerLarge384_build_model(\n",
    "        inputs_dim, num_classes, (input_shape[0], input_shape[1], input_shape[2]))(inputs_dim)\n",
    "\n",
    "    # 第0层的拼接\n",
    "    output_0 = Concatenate(axis=-1,name='build_model_Concatenate_{}'.format(str(0)))([ConvNeXtBase_0,SwinTransformerLarge384_0])\n",
    "    sq0 = tf.keras.Sequential([\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same',kernel_initializer='he_normal',\n",
    "                        name='build_model_conv2D_{}'.format(str(0))),\n",
    "        BatchNormalization(name='build_model_BatchNormalization_{}'.format(str(0))),\n",
    "        ReLU(name='build_model_ReLU_{}'.format(str(0))),\n",
    "        GlobalAveragePooling2D(name='build_model_main_GlobalAveragePooling2D_'+str(0)),\n",
    "        Dropout(0.6, name='build_model_main_Dropout_'+str(0)),\n",
    "        Dense(num_classes,kernel_initializer='he_normal',name='build_model_main_Dense_1_'+str(0)),\n",
    "    ],name='build_model_main_sq0')(output_0)\n",
    "    sq0 = Activation('softmax',name='build_model_main_softmax_'+str(0))(sq0)\n",
    "    # 第1层的拼接\n",
    "    output_1 = Concatenate(axis=-1,name='build_model_Concatenate_{}'.format(str(1)))([ConvNeXtBase_1,SwinTransformerLarge384_1])\n",
    "    sq1 = tf.keras.Sequential([\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same',kernel_initializer='he_normal',\n",
    "                        name='build_model_conv2D_{}'.format(str(1))),\n",
    "        BatchNormalization(name='build_model_BatchNormalization_{}'.format(str(1))),\n",
    "        ReLU(name='build_model_ReLU_{}'.format(str(1))),\n",
    "        GlobalAveragePooling2D(name='build_model_main_GlobalAveragePooling2D_'+str(1)),\n",
    "        Dropout(0.6, name='build_model_main_Dropout_'+str(1)),\n",
    "        Dense(num_classes,kernel_initializer='he_normal',name='build_model_main_Dense_1_'+str(1)),\n",
    "    ],name='build_model_main_sq1')(output_1)\n",
    "    sq1 = Activation('softmax',name='build_model_main_softmax_'+str(1))(sq1)\n",
    "    # 第2层的拼接\n",
    "    output_2 = Concatenate(axis=-1,name='build_model_Concatenate_{}'.format(str(2)))([ConvNeXtBase_2,SwinTransformerLarge384_2])\n",
    "    sq2 = tf.keras.Sequential([\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same',kernel_initializer='he_normal',\n",
    "                        name='build_model_conv2D_{}'.format(str(2))),\n",
    "        BatchNormalization(name='build_model_BatchNormalization_{}'.format(str(2))),\n",
    "        ReLU(name='build_model_ReLU_{}'.format(str(2))),\n",
    "        GlobalAveragePooling2D(name='build_model_main_GlobalAveragePooling2D_'+str(2)),\n",
    "        Dropout(0.6, name='build_model_main_Dropout_'+str(2)),\n",
    "        Dense(num_classes,kernel_initializer='he_normal',name='build_model_main_Dense_1_'+str(2))\n",
    "    ],name='build_model_main_sq2')(output_2)\n",
    "    sq2 = Activation('softmax',name='build_model_main_softmax_'+str(2))(sq2)\n",
    "    \n",
    "    # 第3层的拼接\n",
    "    output_3 = Concatenate(axis=-1,name='build_model_Concatenate_{}'.format(str(3)))([ConvNeXtBase_3,SwinTransformerLarge384_3])\n",
    "    sq3 = tf.keras.Sequential([\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same',kernel_initializer='he_normal',\n",
    "                        name='build_model_conv2D_{}'.format(str(3))),\n",
    "        BatchNormalization(name='build_model_BatchNormalization_{}'.format(str(3))),\n",
    "        ReLU(name='build_model_ReLU_{}'.format(str(3))),\n",
    "        GlobalAveragePooling2D(name='build_model_main_GlobalAveragePooling2D_'+str(3)),\n",
    "        Dropout(0.6, name='build_model_main_Dropout_'+str(3)),\n",
    "        Dense(num_classes,kernel_initializer='he_normal',name='build_model_main_Dense_1_'+str(3)),\n",
    "    ],name='build_model_main_sq')(output_3)\n",
    "    sq3 = Activation('softmax',name='build_model_main_softmax_{}'.format(str(3)))(sq3)\n",
    "    # label的拼接\n",
    "    model = Concatenate(name='build_model_main_Concatenate')([\n",
    "        ConvNeXtBase_num_classes, SwinTransformerLarge384_0_num_classes\n",
    "    ])\n",
    "    model = Dropout(0.6, name='build_model_main_Dropout_1')(model)\n",
    "    model = Dense(512,\n",
    "                    kernel_initializer='he_normal',\n",
    "                    name='build_model_main_Dense_1')(model)\n",
    "    model = LeakyReLU(alpha=0.0001,\n",
    "                    name='build_model_main_LeakyReLU')(\n",
    "                        model)  #此处注意，为sigmoid函数\n",
    "    model = Dropout(0.6, name='build_model_main_Dropout_2')(model)\n",
    "    model = Dense(num_classes,\n",
    "                    kernel_initializer='he_normal',\n",
    "                    name='build_model_main_Dense_2')(model)\n",
    "    All_num_classes = Activation('softmax',\n",
    "                                    name='build_model_All_num_classes')(\n",
    "                                        model)  #此处注意，为sigmoid函数\n",
    "    model = Model(inputs=inputs_dim,\n",
    "                    outputs=[sq0,sq1,sq2,sq3,All_num_classes])\n",
    "    return model\n",
    "\n",
    "height = 256\n",
    "width = 256\n",
    "channels = 3\n",
    "batch_size = 8*4\n",
    "num_classes = 5\n",
    "SEED = 666\n",
    "epochs = 300\n",
    "input_shape = (height, width, channels)\n",
    "model = build_model(num_classes,input_shape)\n",
    "model.load_weights(r'callbacks_EarlyStopping.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_28064\\2904143784.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  test_predict = model.predict_generator(test_generator)#是使用进程还是线\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8400    0.7778    0.8077        27\n",
      "           1     0.8333    0.7692    0.8000        13\n",
      "           2     0.8125    0.8864    0.8478        44\n",
      "           3     0.8182    0.7826    0.8000        23\n",
      "           4     0.9444    0.9444    0.9444        36\n",
      "\n",
      "    accuracy                         0.8531       143\n",
      "   macro avg     0.8497    0.8321    0.8400       143\n",
      "weighted avg     0.8537    0.8531    0.8525       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predict = model.predict_generator(test_generator)#是使用进程还是线\n",
    "\n",
    "test_predict_class_indices = np.argmax(test_predict[-1], axis = 1)#找到预测类别是哪一个   哪个值最大就是哪一类\n",
    "\n",
    "y_test=test_generator.classes\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0', '1', '2','3','4']\n",
    "print(classification_report(y_test, test_predict_class_indices, target_names=target_names,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score为weighted:  0.9579221387204977\n",
      "roc_auc_score为macro:  0.950502536357005\n"
     ]
    }
   ],
   "source": [
    "# AUC值为:\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print('roc_auc_score为weighted: ', roc_auc_score(y_test, test_predict[-1],multi_class='ovr',average='weighted'))\n",
    "print('roc_auc_score为macro: ', roc_auc_score(y_test, test_predict[-1],multi_class='ovo',average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0\\\\18451_20200903_093755_Color_L_006.JPG',\n",
       " '0\\\\18451_20200903_093755_Color_R_003.JPG',\n",
       " '0\\\\18451_20200903_093755_Color_R_005.JPG',\n",
       " '0\\\\18453_20200903_140846_Color_R_001.JPG',\n",
       " '0\\\\18454_20200904_144030_Color_L_007.JPG',\n",
       " '0\\\\18454_20200904_144030_Color_L_009.JPG',\n",
       " '0\\\\18454_20200904_144030_Color_L_010.JPG',\n",
       " '0\\\\18454_20200904_144030_Color_R_006.JPG',\n",
       " '0\\\\18463_20200909_141442_Color_L_001.JPG',\n",
       " '0\\\\18463_20200909_141442_Color_L_009.JPG',\n",
       " '0\\\\18463_20200909_141442_Color_R_001.JPG',\n",
       " '0\\\\18496_20200930_144912_Color_L_006.JPG',\n",
       " '0\\\\18496_20200930_144912_Color_R_007.JPG',\n",
       " '0\\\\18628_20201225_095929_Color_L_002.JPG',\n",
       " '0\\\\18628_20201225_095929_Color_L_003.JPG',\n",
       " '0\\\\18643_20210107_144528_Color_R_002.JPG',\n",
       " '0\\\\18644_20210111_094052_Color_R_001.JPG',\n",
       " '0\\\\18644_20210111_094052_Color_R_002.JPG',\n",
       " '0\\\\18658_20210118_102824_Color_R_002.JPG',\n",
       " '0\\\\18667_20210125_092815_Color_L_001.JPG',\n",
       " '0\\\\18674_20210126_102433_Color_R_001.JPG',\n",
       " '0\\\\18676_20210127_092653_Color_R_001.JPG',\n",
       " '0\\\\18901_20210526_111657_Color_R_002.JPG',\n",
       " '0\\\\C3014_20210303_153521_Color_L_007.JPG',\n",
       " '0\\\\C3014_20210303_153521_Color_R_003.JPG',\n",
       " '0\\\\C3014_20210303_153521_Color_R_004.JPG',\n",
       " '0\\\\C3014_20210303_153521_Color_R_007.JPG',\n",
       " '1\\\\18604_20201214_154914_Color_L_003.JPG',\n",
       " '1\\\\18604_20201214_154914_Color_R_001.JPG',\n",
       " '1\\\\18604_20201214_154914_Color_R_003.JPG',\n",
       " '1\\\\18806_20210402_160500_Color_L_002.JPG',\n",
       " '1\\\\18813_20210408_142422_Color_R_002.JPG',\n",
       " '1\\\\18825_20210414_092616_Color_L_003.JPG',\n",
       " '1\\\\18825_20210414_092616_Color_R_001.JPG',\n",
       " '1\\\\18946_20210616_153240_Color_R_005.JPG',\n",
       " '1\\\\18951_20210618_140826_Color_L_001.JPG',\n",
       " '1\\\\9332_20200701_141815_Color_R_009.JPG',\n",
       " '1\\\\C2998_20210224_112843_Color_R_001.JPG',\n",
       " '1\\\\C2998_20210224_112843_Color_R_003.JPG',\n",
       " '1\\\\C2998_20210224_112843_Color_R_005.JPG',\n",
       " '2\\\\15845_20170217_113102_Color (OSCAR)_R_002.JPG',\n",
       " '2\\\\17155_20180813_144706_Color (OSCAR)_L_002.JPG',\n",
       " '2\\\\17155_20180813_144706_Color (OSCAR)_L_004.JPG',\n",
       " '2\\\\18026_20191008_150050_Color_L_003.JPG',\n",
       " '2\\\\18026_20191008_150050_Color_L_006.JPG',\n",
       " '2\\\\18026_20191008_150050_Color_L_007.JPG',\n",
       " '2\\\\18026_20191008_150050_Color_L_008.JPG',\n",
       " '2\\\\18026_20191008_150050_Color_L_009.JPG',\n",
       " '2\\\\18026_20191008_150050_Color_L_015.JPG',\n",
       " '2\\\\18026_20191008_150050_Color_L_019.JPG',\n",
       " '2\\\\18026_20191008_150050_Color_L_020.JPG',\n",
       " '2\\\\18026_20191008_150050_Color_R_005.JPG',\n",
       " '2\\\\18026_20191008_150050_Color_R_007.JPG',\n",
       " '2\\\\18026_20191008_150050_Color_R_011.JPG',\n",
       " '2\\\\18026_20191008_150050_Color_R_018.JPG',\n",
       " '2\\\\18476_20200917_100920_Color_L_002.JPG',\n",
       " '2\\\\18478_20200917_143204_Color_R_008.JPG',\n",
       " '2\\\\18488_20200924_105227_Color_L_001.JPG',\n",
       " '2\\\\18488_20200924_105227_Color_L_007.JPG',\n",
       " '2\\\\18488_20200924_105227_Color_R_002.JPG',\n",
       " '2\\\\18488_20200924_105227_Color_R_010.JPG',\n",
       " '2\\\\18492_20200929_151252_Color_R_002.JPG',\n",
       " '2\\\\18498_20201009_093922_Color_R_005.JPG',\n",
       " '2\\\\18498_20201009_093922_Color_R_011.JPG',\n",
       " '2\\\\18505_20201014_144012_Color_L_001.JPG',\n",
       " '2\\\\18505_20201014_144012_Color_L_002.JPG',\n",
       " '2\\\\18505_20201014_144012_Color_L_004.JPG',\n",
       " '2\\\\18505_20201014_144012_Color_L_007.JPG',\n",
       " '2\\\\18505_20201014_144012_Color_L_008.JPG',\n",
       " '2\\\\18728_20210226_153542_Color_L_001.JPG',\n",
       " '2\\\\18740_20210304_150043_Color_R_001.JPG',\n",
       " '2\\\\18785_20210324_143425_Color_R_008.JPG',\n",
       " '2\\\\18793_20210331_104445_Color_R_002.JPG',\n",
       " '2\\\\18833_20210416_150744_Color_L_001.JPG',\n",
       " '2\\\\18833_20210416_150744_Color_R_001.JPG',\n",
       " '2\\\\18877_20210513_101916_Color_R_001.JPG',\n",
       " '2\\\\18877_20210513_101916_Color_R_002.JPG',\n",
       " '2\\\\18877_20210513_101916_Color_R_006.JPG',\n",
       " '2\\\\18877_20210513_101916_Color_R_009.JPG',\n",
       " '2\\\\C2746_20191101_135549_Color_L_006.JPG',\n",
       " '2\\\\C2746_20191101_135549_Color_R_003.JPG',\n",
       " '2\\\\C2746_20191101_135549_Color_R_006.JPG',\n",
       " '2\\\\C2746_20191101_135549_Color_R_009.JPG',\n",
       " '2\\\\c2815_20200415_145833_Color_L_005.JPG',\n",
       " '3\\\\15845_20170217_113102_Color (OSCAR)_L_001.JPG',\n",
       " '3\\\\17471_20190123_093818_Color (OSCAR)_L_001.JPG',\n",
       " '3\\\\17765_20190612_101359_Color_L_001.JPG',\n",
       " '3\\\\18014_20190927_093004_Color_R_001.JPG',\n",
       " '3\\\\18014_20200924_095828_Color_L_011.JPG',\n",
       " '3\\\\18014_20200924_095828_Color_R_002.JPG',\n",
       " '3\\\\18014_20200924_095828_Color_R_005.JPG',\n",
       " '3\\\\18014_20200924_095828_Color_R_012.JPG',\n",
       " '3\\\\18471_20200915_145817_Color_L_002.JPG',\n",
       " '3\\\\18471_20200915_145817_Color_L_010.JPG',\n",
       " '3\\\\18471_20200915_145817_Color_L_011.JPG',\n",
       " '3\\\\18471_20200915_145817_Color_R_001.JPG',\n",
       " '3\\\\18486_20200923_152652_Color_L_001.JPG',\n",
       " '3\\\\18486_20200923_152652_Color_L_003.JPG',\n",
       " '3\\\\18486_20200923_152652_Color_L_011.JPG',\n",
       " '3\\\\18490_20200929_094752_Color_L_001.JPG',\n",
       " '3\\\\18579_20201202_093219_Color_R_002.JPG',\n",
       " '3\\\\18586_20201203_104348_Color_L_002.JPG',\n",
       " '3\\\\18586_20201203_104348_Color_R_001.JPG',\n",
       " '3\\\\18973_20210628_151814_Color_R_001.JPG',\n",
       " '3\\\\18999_20210707_112716_Color_L_001.JPG',\n",
       " '3\\\\C3108_20210621_142602_Color_L_008.JPG',\n",
       " '3\\\\C3108_20210621_142602_Color_L_009.JPG',\n",
       " '4\\\\17607_20190401_141758_Color_R_002.JPG',\n",
       " '4\\\\18486_20200923_152652_Color_R_001.JPG',\n",
       " '4\\\\18596_20201208_144309_Color_R_001.JPG',\n",
       " '4\\\\18596_20201208_144309_Color_R_003.JPG',\n",
       " '4\\\\18625_20201223_145932_Color_L_001.JPG',\n",
       " '4\\\\18647_20210111_103537_Color_R_003.JPG',\n",
       " '4\\\\18647_20210111_103537_Color_R_009.JPG',\n",
       " '4\\\\18647_20210111_103537_Color_R_012.JPG',\n",
       " '4\\\\18662_20210121_102140_Color_L_001.JPG',\n",
       " '4\\\\18700_20210210_102619_Color_L_001.JPG',\n",
       " '4\\\\18700_20210210_102619_Color_L_002.JPG',\n",
       " '4\\\\18730_20210301_143344_Color_L_004.JPG',\n",
       " '4\\\\18741_20210304_154119_Color_L_001.JPG',\n",
       " '4\\\\18793_20210331_104445_Color_L_001.JPG',\n",
       " '4\\\\18804_20210402_094330_Color_L_001.JPG',\n",
       " '4\\\\18937_20210609_154443_Color_L_002.JPG',\n",
       " '4\\\\18937_20210609_154443_Color_L_003.JPG',\n",
       " '4\\\\18937_20210609_154443_Color_R_002.JPG',\n",
       " '4\\\\18937_20210609_154443_Color_R_003.JPG',\n",
       " '4\\\\C2648_20190523_130938_Color_R_005.JPG',\n",
       " '4\\\\C2861_20200827_102512_Color_L_003.JPG',\n",
       " '4\\\\C2861_20200827_102512_Color_L_004.JPG',\n",
       " '4\\\\C2861_20200827_102512_Color_R_001.JPG',\n",
       " '4\\\\C2861_20200827_102512_Color_R_002.JPG',\n",
       " '4\\\\C2861_20200827_102512_Color_R_004.JPG',\n",
       " '4\\\\C2861_20200827_102512_Color_R_006.JPG',\n",
       " '4\\\\C3103_20210611_110909_Color_L_001.JPG',\n",
       " '4\\\\C3113_20210630_095940_Color_L_002.JPG',\n",
       " '4\\\\C3113_20210630_095940_Color_L_005.JPG',\n",
       " '4\\\\C3119_20210707_142423_Color_L_001.JPG',\n",
       " '4\\\\C3119_20210707_142423_Color_L_004.JPG',\n",
       " '4\\\\C3119_20210707_142423_Color_R_008.JPG',\n",
       " '4\\\\C3119_20210707_142423_Color_R_011.JPG',\n",
       " '4\\\\c2882_20200916_143844_Color_R_001.JPG',\n",
       " '4\\\\c2882_20200916_143844_Color_R_004.JPG',\n",
       " '4\\\\c2882_20200916_143844_Color_R_007.JPG']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 2, 3, 0, 0, 2, 0, 0, 0, 3, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2,\n",
       "       4, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 3, 3, 3,\n",
       "       3, 3, 2, 3, 4, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 2, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict_class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21,  2,  2,  2,  0],\n",
       "       [ 1, 10,  2,  0,  0],\n",
       "       [ 3,  0, 39,  1,  1],\n",
       "       [ 0,  0,  4, 18,  1],\n",
       "       [ 0,  0,  1,  1, 34]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, test_predict_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca05fde7429b27a1e3c911dbfbe35bb175add377b8c652b2124f732d4b1dc45e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
